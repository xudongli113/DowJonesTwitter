<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><title>Cloud9: A MapReduce Library for Hadoop</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" href="../style.css" type="text/css" />
</head>

<body>

<center><table width="80%"><tbody><tr><td align="left">

<h2>Cloud<sup><small>9</small></sup>: Primer on MapReduce algorithm
design</h2>

<p>by Jimmy Lin</p>

<p>
<small>(Page first created: 20 Nov 2007; last updated:
<script language="JavaScript" type="text/javascript">
<!--
var LastUpdated = "$Date$";
LastUpdated = LastUpdated.substring(LastUpdated.length-14, LastUpdated.length-3);
document.writeln (LastUpdated+")");
-->
</script>
</small>
</p>

<div class="main">

<h3>Introduction</h3>

<p>This guide is intended to provide an introduction to answering the
following question: How do I coordinate partial results in a MapReduce
algorithm, given that all the mappers run in parallel and in
isolation?  In short, you have to hide synchronization in the reduce
phase.  This guide illustrates the three tools at your disposal to
accomplish this:</p>

<ul>

  <li>The ability to hold state in the reducer across multiple
  key-value pairs.</li>

  <li>The ability to control sort order of keys.</li>

  <li>The ability to specify different partitioners.</li>

</ul>

<p>In short, you want to sort the key-value pairs in the order you
wish to use them in your computation, and then have the reducer
perform that computation when the key-value pairs arrive.  The
partitioner ensures that all the key-value pairs you need arrive at
the correct reducer.  This will be illustrated with the task of
computing simple conditional probabilities.</p>

<h3>The Problem</h3>

<p>The relevant example we'll discuss
is <code>DemoWordCondProbTuple</code> in
Cloud<sup><small>9</small></sup>, which builds on
<code>DemoWordCountTuple1</code>.  Note
that <code>DemoWordCondProbJSON</code> does the same thing, except
using JSON objects instead.  <code>DemoWordCountTuple1</code>
generates tuples of the following form:</p>

<pre>
...
(admirable, 0)    9
(admirable, 1)    6
(admiral, 0)      2
(admiral, 1)      4
(admiration, 0)  10
(admiration, 1)   6
(admire, 0)       5
(admire, 1)       3
(admired, 0)     12
(admired, 1)      7
...
</pre>

<p>The key is a tuple.  The first field of the tuple contains a token,
the second field indicates whether it was found on a even-length or
odd-length line. The value is the count of the tuple occurrences in
the collection.</p>

<p><code>DemoWordCondProbTuple</code> generates tuples of the
following form:</p>

<pre>
...
(admirable, *)   15.0
(admirable, 0)   0.6
(admirable, 1)   0.4
(admiral, *)     6.0
(admiral, 0)     0.33333334
(admiral, 1)     0.6666667
(admiration, *)  16.0
(admiration, 0)  0.625
(admiration, 1)  0.375
(admire, *)      8.0
(admire, 0)      0.625
(admire, 1)      0.375
(admired, *)     19.0
(admired, 0)     0.6315789
(admired, 1)     0.36842105
...
</pre>

<p>In other words, the demo converts the count into conditional
probabilities, i.e., <code>p(EvenOrOdd|token)</code>.  How is this
accomplished?  Using exactly the three tools described above.</p>

<h3>The Solution</h3>

<p>First, we need the count of each token, independent of what type of
line it appeared on.  We can accomplish this by emitting (admirable,*)
every time we see the word "admirable", in addition to either
(admirable,0) or (admirable,1) as appropriate.</p>

<p>Intuitively, to compute the conditional probability, we first need
to get the total count, and then divide the conditional counts by the
total count.  In other words, we need to compute:</p>

<ul>
  <li>(admirable,0)/(admirable,*)</li>
  <li>(admirable,1)/(admirable,*)</li>
</ul>

<p>This is accomplished by making sure that (admirable,*) comes before
either of the other tuples in the reduce phase.  Thus, when the
reducer receives (admirable,*), it can hold the value in memory (i.e.,
the reducer can hold state across multiple key-value pairs).  When
(admirable,0) or (admirable,1) arrives afterward, the reducer can
simply divide by the total count, computing the two quantities above.
The computed probability is then emitted as the final value (with the
same key).  We enforce the order in which the key-value pairs arrive
at the reducer by controlling the sort order of the keys&mdash;which
is defined by its comparator.  In the case of the Tuple class, you
don't actually need to do anything since the Tuple already defines a
natural ordering consistent with this computation (i.e., Tuples with
special symbols get sorted first).</p>

<p>There is one more thing needed to make this work.  The Hadoop
<code>Partitioner</code> is responsible for splitting the key space
and determining which reducer a key-value pair gets sent
to. <code>HashPartitioner</code> is the default Partitioner, which
simply takes the hash value of the key and mods it by the number of
reduce tasks.  The problem with this is that (admirable,0),
(admirable,1), (admirable,*) may be sent to different
reducers... which would cause the above algorithm to fail.</p>

<p>The solution is to write a custom <code>Partitioner</code> that
only pays attention to the token.  That is, the partitioner uses the
hashcode of the token (not the entire key) to determine which reduce
task the key gets sent to.  The <code>setPartitionerClass</code>
in <code>JobConf</code> allows you to specify a custom
partitioner.</p>

<p><b>Potential gotcha:</b> Be very careful in your use of a
<code>Combiner</code> class!  In the basic word count demo, the
reducer can also be used as the combiner, since all it did was compute
the sum (i.e., the operation is both associative and commutative).
This is no longer the case for the reducer in
<code>DemoWordCondProb</code>, since there's a division at the end to
compute the conditional probability.  As a result, this <i>must</i>
happen at the reduce stage, because only then are you guaranteed that
all values with the same key have been collected.  So, use the
identity combiner; or write a custom combiner that simply sums the
partial counts.</p>

<h3>Postscript</h3>

<p>For more details, including a more efficient way to compute
conditional probabilities, see the following paper:</p>

<blockquote>Jimmy
Lin. (2008) <a href="../papers/Lin_EMNLP2008.pdf">Scalable Language
Processing Algorithms for the Masses: A Case Study in Computing Word
Co-occurrence Matrices with MapReduce.</a> Proceedings of the 2008
Conference on Empirical Methods in Natural Language Processing (EMNLP
2008).</blockquote>

<p>What I described above corresponds to the "pairs" algorithm
discussed in the paper.</p>

<p style="padding-top: 25px"><a href="../index.html">Back to main page</a></p>

</div>

<table width="100%" border="0" cellpadding="0" cellspacing="0" style="padding-top: 10px;">
<tr><td valign="top" align="left"></td>
<td valign="top" align="right">
  <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/us/">
  <img src="../images/creative-commons.png" border="0" alt="Creative Commons: Attribution-Noncommercial-Share Alike 3.0 United States"/>
  </a>
  <a href="http://validator.w3.org/check/referer">
  <img src="../images/valid-xhtml10.gif" border="0"
       alt="Valid XHTML 1.0!" height="31" width="88" />
  </a>
  <a href="http://jigsaw.w3.org/css-validator/check/referer">
  <img style="border:0;width:88px;height:31px"
       src="../images/vcss.gif" 
       alt="Valid CSS!" />
  </a>
</td></tr></table>

</td></tr></tbody></table></center>

</body></html>
